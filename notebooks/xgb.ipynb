{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score as R2\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Age</th>\n",
       "      <th>BodyweightKg</th>\n",
       "      <th>Best3SquatKg</th>\n",
       "      <th>Best3BenchKg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63.20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63.20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.20</td>\n",
       "      <td>62.5</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.90</td>\n",
       "      <td>105.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>94.30</td>\n",
       "      <td>140.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93451</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.5</td>\n",
       "      <td>88.70</td>\n",
       "      <td>37.5</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93453</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>71.34</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93454</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>70.40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93455</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>69.90</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93456 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex_F  Sex_M   Age  BodyweightKg  Best3SquatKg  Best3BenchKg\n",
       "0          0      1  13.0         63.20         120.0          77.5\n",
       "1          0      1  13.0         63.20         120.0          77.5\n",
       "2          1      0  13.0         44.20          62.5          42.5\n",
       "3          1      0  13.0         65.90         105.0          60.0\n",
       "4          0      1  13.0         94.30         140.0         110.0\n",
       "...      ...    ...   ...           ...           ...           ...\n",
       "93451      0      1  85.0         80.60          65.0          80.0\n",
       "93452      0      1  85.5         88.70          37.5          55.0\n",
       "93453      1      0  90.0         71.34          20.0          30.0\n",
       "93454      1      0  91.5         70.40          20.0          30.0\n",
       "93455      1      0  92.0         69.90          20.0          25.0\n",
       "\n",
       "[93456 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import model training data\n",
    "data = pd.read_csv('../data/encoded_training_data.csv')\n",
    "\n",
    "# Separate features from target\n",
    "X, y = data[['Sex_F', 'Sex_M', 'Age', 'BodyweightKg', 'Best3SquatKg', 'Best3BenchKg']], data['Best3DeadliftKg']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.9104610193483963\n",
      "MSE:  287.565841\n",
      "RMSE:  16.957766\n"
     ]
    }
   ],
   "source": [
    "# Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                      test_size = 0.3, random_state = 123)\n",
    "  \n",
    "# Instantiation\n",
    "xgb_r = xgb.XGBRegressor(objective ='reg:squarederror',\n",
    "                  n_estimators = 200, seed = 123)\n",
    "  \n",
    "# Fitting the model\n",
    "xgb_r.fit(X_train, y_train)\n",
    "  \n",
    "# Predict the model\n",
    "pred = xgb_r.predict(X_test)\n",
    "  \n",
    "# MSE and RMSE Computation\n",
    "mse = MSE(y_test, pred)\n",
    "r2 = R2(y_test, pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'r2: {r2}')\n",
    "print(\"MSE: % f\" %(mse))\n",
    "print(\"RMSE: % f\" %(rmse))\n",
    "\n",
    "xgb_r.save_model(\"../models/deadlift.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:193.68144\tvalidation-rmse:193.32722\n",
      "[1]\ttrain-rmse:191.76684\tvalidation-rmse:191.41487\n",
      "[2]\ttrain-rmse:189.87156\tvalidation-rmse:189.52153\n",
      "[3]\ttrain-rmse:187.99548\tvalidation-rmse:187.64752\n",
      "[4]\ttrain-rmse:186.13834\tvalidation-rmse:185.79268\n",
      "[5]\ttrain-rmse:184.29997\tvalidation-rmse:183.95588\n",
      "[6]\ttrain-rmse:182.48019\tvalidation-rmse:182.13880\n",
      "[7]\ttrain-rmse:180.67873\tvalidation-rmse:180.33951\n",
      "[8]\ttrain-rmse:178.89554\tvalidation-rmse:178.55906\n",
      "[9]\ttrain-rmse:177.13032\tvalidation-rmse:176.79594\n",
      "[10]\ttrain-rmse:175.38300\tvalidation-rmse:175.05145\n",
      "[11]\ttrain-rmse:173.65331\tvalidation-rmse:173.32382\n",
      "[12]\ttrain-rmse:171.94108\tvalidation-rmse:171.61470\n",
      "[13]\ttrain-rmse:170.24605\tvalidation-rmse:169.92193\n",
      "[14]\ttrain-rmse:168.56820\tvalidation-rmse:168.24631\n",
      "[15]\ttrain-rmse:166.90729\tvalidation-rmse:166.58840\n",
      "[16]\ttrain-rmse:165.26322\tvalidation-rmse:164.94652\n",
      "[17]\ttrain-rmse:163.63565\tvalidation-rmse:163.32192\n",
      "[18]\ttrain-rmse:162.02471\tvalidation-rmse:161.71309\n",
      "[19]\ttrain-rmse:160.42992\tvalidation-rmse:160.12118\n",
      "[20]\ttrain-rmse:158.85138\tvalidation-rmse:158.54459\n",
      "[21]\ttrain-rmse:157.28876\tvalidation-rmse:156.98366\n",
      "[22]\ttrain-rmse:155.74191\tvalidation-rmse:155.43964\n",
      "[23]\ttrain-rmse:154.21082\tvalidation-rmse:153.91040\n",
      "[24]\ttrain-rmse:152.69512\tvalidation-rmse:152.39654\n",
      "[25]\ttrain-rmse:151.19467\tvalidation-rmse:150.89825\n",
      "[26]\ttrain-rmse:149.70949\tvalidation-rmse:149.41530\n",
      "[27]\ttrain-rmse:148.23944\tvalidation-rmse:147.94793\n",
      "[28]\ttrain-rmse:146.78423\tvalidation-rmse:146.49497\n",
      "[29]\ttrain-rmse:145.34334\tvalidation-rmse:145.05619\n",
      "[30]\ttrain-rmse:143.91765\tvalidation-rmse:143.63223\n",
      "[31]\ttrain-rmse:142.50595\tvalidation-rmse:142.22281\n",
      "[32]\ttrain-rmse:141.10846\tvalidation-rmse:140.82725\n",
      "[33]\ttrain-rmse:139.72518\tvalidation-rmse:139.44591\n",
      "[34]\ttrain-rmse:138.35608\tvalidation-rmse:138.07910\n",
      "[35]\ttrain-rmse:137.00063\tvalidation-rmse:136.72556\n",
      "[36]\ttrain-rmse:135.65949\tvalidation-rmse:135.38669\n",
      "[37]\ttrain-rmse:134.33147\tvalidation-rmse:134.06074\n",
      "[38]\ttrain-rmse:133.01709\tvalidation-rmse:132.74847\n",
      "[39]\ttrain-rmse:131.71639\tvalidation-rmse:131.44974\n",
      "[40]\ttrain-rmse:130.42846\tvalidation-rmse:130.16326\n",
      "[41]\ttrain-rmse:129.15365\tvalidation-rmse:128.88982\n",
      "[42]\ttrain-rmse:127.89176\tvalidation-rmse:127.62997\n",
      "[43]\ttrain-rmse:126.64313\tvalidation-rmse:126.38307\n",
      "[44]\ttrain-rmse:125.40688\tvalidation-rmse:125.14854\n",
      "[45]\ttrain-rmse:124.18316\tvalidation-rmse:123.92671\n",
      "[46]\ttrain-rmse:122.97177\tvalidation-rmse:122.71729\n",
      "[47]\ttrain-rmse:121.77297\tvalidation-rmse:121.52071\n",
      "[48]\ttrain-rmse:120.58619\tvalidation-rmse:120.33578\n",
      "[49]\ttrain-rmse:119.41187\tvalidation-rmse:119.16241\n",
      "[50]\ttrain-rmse:118.24917\tvalidation-rmse:118.00149\n",
      "[51]\ttrain-rmse:117.09848\tvalidation-rmse:116.85256\n",
      "[52]\ttrain-rmse:115.95957\tvalidation-rmse:115.71609\n",
      "[53]\ttrain-rmse:114.83212\tvalidation-rmse:114.59051\n",
      "[54]\ttrain-rmse:113.71624\tvalidation-rmse:113.47630\n",
      "[55]\ttrain-rmse:112.61220\tvalidation-rmse:112.37372\n",
      "[56]\ttrain-rmse:111.51915\tvalidation-rmse:111.28252\n",
      "[57]\ttrain-rmse:110.43733\tvalidation-rmse:110.20225\n",
      "[58]\ttrain-rmse:109.36686\tvalidation-rmse:109.13324\n",
      "[59]\ttrain-rmse:108.30687\tvalidation-rmse:108.07469\n",
      "[60]\ttrain-rmse:107.25774\tvalidation-rmse:107.02719\n",
      "[61]\ttrain-rmse:106.21935\tvalidation-rmse:105.99052\n",
      "[62]\ttrain-rmse:105.19211\tvalidation-rmse:104.96439\n",
      "[63]\ttrain-rmse:104.17495\tvalidation-rmse:103.94858\n",
      "[64]\ttrain-rmse:103.16818\tvalidation-rmse:102.94365\n",
      "[65]\ttrain-rmse:102.17184\tvalidation-rmse:101.94869\n",
      "[66]\ttrain-rmse:101.18584\tvalidation-rmse:100.96391\n",
      "[67]\ttrain-rmse:100.20984\tvalidation-rmse:99.98969\n",
      "[68]\ttrain-rmse:99.24425\tvalidation-rmse:99.02536\n",
      "[69]\ttrain-rmse:98.28828\tvalidation-rmse:98.07127\n",
      "[70]\ttrain-rmse:97.34217\tvalidation-rmse:97.12650\n",
      "[71]\ttrain-rmse:96.40573\tvalidation-rmse:96.19159\n",
      "[72]\ttrain-rmse:95.47914\tvalidation-rmse:95.26575\n",
      "[73]\ttrain-rmse:94.56205\tvalidation-rmse:94.34987\n",
      "[74]\ttrain-rmse:93.65469\tvalidation-rmse:93.44341\n",
      "[75]\ttrain-rmse:92.75635\tvalidation-rmse:92.54666\n",
      "[76]\ttrain-rmse:91.86752\tvalidation-rmse:91.65931\n",
      "[77]\ttrain-rmse:90.98759\tvalidation-rmse:90.78104\n",
      "[78]\ttrain-rmse:90.11621\tvalidation-rmse:89.91119\n",
      "[79]\ttrain-rmse:89.25460\tvalidation-rmse:89.05081\n",
      "[80]\ttrain-rmse:88.40123\tvalidation-rmse:88.19896\n",
      "[81]\ttrain-rmse:87.55727\tvalidation-rmse:87.35639\n",
      "[82]\ttrain-rmse:86.72207\tvalidation-rmse:86.52290\n",
      "[83]\ttrain-rmse:85.89501\tvalidation-rmse:85.69728\n",
      "[84]\ttrain-rmse:85.07676\tvalidation-rmse:84.88033\n",
      "[85]\ttrain-rmse:84.26685\tvalidation-rmse:84.07185\n",
      "[86]\ttrain-rmse:83.46559\tvalidation-rmse:83.27183\n",
      "[87]\ttrain-rmse:82.67249\tvalidation-rmse:82.47996\n",
      "[88]\ttrain-rmse:81.88788\tvalidation-rmse:81.69674\n",
      "[89]\ttrain-rmse:81.11177\tvalidation-rmse:80.92177\n",
      "[90]\ttrain-rmse:80.34332\tvalidation-rmse:80.15427\n",
      "[91]\ttrain-rmse:79.58315\tvalidation-rmse:79.39548\n",
      "[92]\ttrain-rmse:78.83071\tvalidation-rmse:78.64399\n",
      "[93]\ttrain-rmse:78.08626\tvalidation-rmse:77.90074\n",
      "[94]\ttrain-rmse:77.34957\tvalidation-rmse:77.16498\n",
      "[95]\ttrain-rmse:76.62068\tvalidation-rmse:76.43738\n",
      "[96]\ttrain-rmse:75.89960\tvalidation-rmse:75.71709\n",
      "[97]\ttrain-rmse:75.18596\tvalidation-rmse:75.00459\n",
      "[98]\ttrain-rmse:74.47987\tvalidation-rmse:74.29953\n",
      "[99]\ttrain-rmse:73.78130\tvalidation-rmse:73.60150\n",
      "[100]\ttrain-rmse:73.08981\tvalidation-rmse:72.91113\n",
      "[101]\ttrain-rmse:72.40571\tvalidation-rmse:72.22813\n",
      "[102]\ttrain-rmse:71.72890\tvalidation-rmse:71.55252\n",
      "[103]\ttrain-rmse:71.05928\tvalidation-rmse:70.88385\n",
      "[104]\ttrain-rmse:70.39681\tvalidation-rmse:70.22245\n",
      "[105]\ttrain-rmse:69.74130\tvalidation-rmse:69.56805\n",
      "[106]\ttrain-rmse:69.09257\tvalidation-rmse:68.92017\n",
      "[107]\ttrain-rmse:68.45102\tvalidation-rmse:68.27914\n",
      "[108]\ttrain-rmse:67.81618\tvalidation-rmse:67.64537\n",
      "[109]\ttrain-rmse:67.18795\tvalidation-rmse:67.01824\n",
      "[110]\ttrain-rmse:66.56656\tvalidation-rmse:66.39809\n",
      "[111]\ttrain-rmse:65.95180\tvalidation-rmse:65.78421\n",
      "[112]\ttrain-rmse:65.34345\tvalidation-rmse:65.17707\n",
      "[113]\ttrain-rmse:64.74177\tvalidation-rmse:64.57628\n",
      "[114]\ttrain-rmse:64.14642\tvalidation-rmse:63.98157\n",
      "[115]\ttrain-rmse:63.55729\tvalidation-rmse:63.39351\n",
      "[116]\ttrain-rmse:62.97473\tvalidation-rmse:62.81186\n",
      "[117]\ttrain-rmse:62.39798\tvalidation-rmse:62.23652\n",
      "[118]\ttrain-rmse:61.82779\tvalidation-rmse:61.66669\n",
      "[119]\ttrain-rmse:61.26381\tvalidation-rmse:61.10339\n",
      "[120]\ttrain-rmse:60.70572\tvalidation-rmse:60.54633\n",
      "[121]\ttrain-rmse:60.15355\tvalidation-rmse:59.99527\n",
      "[122]\ttrain-rmse:59.60764\tvalidation-rmse:59.45001\n",
      "[123]\ttrain-rmse:59.06727\tvalidation-rmse:58.91083\n",
      "[124]\ttrain-rmse:58.53295\tvalidation-rmse:58.37730\n",
      "[125]\ttrain-rmse:58.00415\tvalidation-rmse:57.84961\n",
      "[126]\ttrain-rmse:57.48156\tvalidation-rmse:57.32761\n",
      "[127]\ttrain-rmse:56.96429\tvalidation-rmse:56.81136\n",
      "[128]\ttrain-rmse:56.45267\tvalidation-rmse:56.30096\n",
      "[129]\ttrain-rmse:55.94703\tvalidation-rmse:55.79571\n",
      "[130]\ttrain-rmse:55.44659\tvalidation-rmse:55.29630\n",
      "[131]\ttrain-rmse:54.95180\tvalidation-rmse:54.80209\n",
      "[132]\ttrain-rmse:54.46224\tvalidation-rmse:54.31334\n",
      "[133]\ttrain-rmse:53.97839\tvalidation-rmse:53.83019\n",
      "[134]\ttrain-rmse:53.49985\tvalidation-rmse:53.35237\n",
      "[135]\ttrain-rmse:53.02634\tvalidation-rmse:52.87964\n",
      "[136]\ttrain-rmse:52.55796\tvalidation-rmse:52.41224\n",
      "[137]\ttrain-rmse:52.09513\tvalidation-rmse:51.95024\n",
      "[138]\ttrain-rmse:51.63712\tvalidation-rmse:51.49330\n",
      "[139]\ttrain-rmse:51.18431\tvalidation-rmse:51.04123\n",
      "[140]\ttrain-rmse:50.73674\tvalidation-rmse:50.59443\n",
      "[141]\ttrain-rmse:50.29381\tvalidation-rmse:50.15207\n",
      "[142]\ttrain-rmse:49.85586\tvalidation-rmse:49.71504\n",
      "[143]\ttrain-rmse:49.42313\tvalidation-rmse:49.28302\n",
      "[144]\ttrain-rmse:48.99481\tvalidation-rmse:48.85521\n",
      "[145]\ttrain-rmse:48.57168\tvalidation-rmse:48.43264\n",
      "[146]\ttrain-rmse:48.15306\tvalidation-rmse:48.01495\n",
      "[147]\ttrain-rmse:47.73906\tvalidation-rmse:47.60143\n",
      "[148]\ttrain-rmse:47.33019\tvalidation-rmse:47.19340\n",
      "[149]\ttrain-rmse:46.92553\tvalidation-rmse:46.78916\n",
      "[150]\ttrain-rmse:46.52560\tvalidation-rmse:46.39009\n",
      "[151]\ttrain-rmse:46.13011\tvalidation-rmse:45.99499\n",
      "[152]\ttrain-rmse:45.73944\tvalidation-rmse:45.60506\n",
      "[153]\ttrain-rmse:45.35295\tvalidation-rmse:45.21895\n",
      "[154]\ttrain-rmse:44.97110\tvalidation-rmse:44.83756\n",
      "[155]\ttrain-rmse:44.59345\tvalidation-rmse:44.46022\n",
      "[156]\ttrain-rmse:44.22016\tvalidation-rmse:44.08776\n",
      "[157]\ttrain-rmse:43.85142\tvalidation-rmse:43.71949\n",
      "[158]\ttrain-rmse:43.48687\tvalidation-rmse:43.35543\n",
      "[159]\ttrain-rmse:43.12651\tvalidation-rmse:42.99524\n",
      "[160]\ttrain-rmse:42.77010\tvalidation-rmse:42.63924\n",
      "[161]\ttrain-rmse:42.41797\tvalidation-rmse:42.28760\n",
      "[162]\ttrain-rmse:42.07007\tvalidation-rmse:41.93997\n",
      "[163]\ttrain-rmse:41.72605\tvalidation-rmse:41.59610\n",
      "[164]\ttrain-rmse:41.38631\tvalidation-rmse:41.25677\n",
      "[165]\ttrain-rmse:41.05025\tvalidation-rmse:40.92095\n",
      "[166]\ttrain-rmse:40.71819\tvalidation-rmse:40.58968\n",
      "[167]\ttrain-rmse:40.39030\tvalidation-rmse:40.26224\n",
      "[168]\ttrain-rmse:40.06616\tvalidation-rmse:39.93824\n",
      "[169]\ttrain-rmse:39.74599\tvalidation-rmse:39.61833\n",
      "[170]\ttrain-rmse:39.42937\tvalidation-rmse:39.30191\n",
      "[171]\ttrain-rmse:39.11667\tvalidation-rmse:38.98963\n",
      "[172]\ttrain-rmse:38.80784\tvalidation-rmse:38.68097\n",
      "[173]\ttrain-rmse:38.50241\tvalidation-rmse:38.37572\n",
      "[174]\ttrain-rmse:38.20091\tvalidation-rmse:38.07441\n",
      "[175]\ttrain-rmse:37.90283\tvalidation-rmse:37.77645\n",
      "[176]\ttrain-rmse:37.60864\tvalidation-rmse:37.48245\n",
      "[177]\ttrain-rmse:37.31768\tvalidation-rmse:37.19175\n",
      "[178]\ttrain-rmse:37.03049\tvalidation-rmse:36.90479\n",
      "[179]\ttrain-rmse:36.74664\tvalidation-rmse:36.62134\n",
      "[180]\ttrain-rmse:36.46623\tvalidation-rmse:36.34113\n",
      "[181]\ttrain-rmse:36.18940\tvalidation-rmse:36.06437\n",
      "[182]\ttrain-rmse:35.91583\tvalidation-rmse:35.79109\n",
      "[183]\ttrain-rmse:35.64563\tvalidation-rmse:35.52139\n",
      "[184]\ttrain-rmse:35.37898\tvalidation-rmse:35.25480\n",
      "[185]\ttrain-rmse:35.11547\tvalidation-rmse:34.99123\n",
      "[186]\ttrain-rmse:34.85530\tvalidation-rmse:34.73101\n",
      "[187]\ttrain-rmse:34.59828\tvalidation-rmse:34.47421\n",
      "[188]\ttrain-rmse:34.34446\tvalidation-rmse:34.22073\n",
      "[189]\ttrain-rmse:34.09389\tvalidation-rmse:33.96997\n",
      "[190]\ttrain-rmse:33.84647\tvalidation-rmse:33.72277\n",
      "[191]\ttrain-rmse:33.60212\tvalidation-rmse:33.47884\n",
      "[192]\ttrain-rmse:33.36086\tvalidation-rmse:33.23775\n",
      "[193]\ttrain-rmse:33.12253\tvalidation-rmse:32.99956\n",
      "[194]\ttrain-rmse:32.88733\tvalidation-rmse:32.76465\n",
      "[195]\ttrain-rmse:32.65524\tvalidation-rmse:32.53261\n",
      "[196]\ttrain-rmse:32.42596\tvalidation-rmse:32.30337\n",
      "[197]\ttrain-rmse:32.19957\tvalidation-rmse:32.07712\n",
      "[198]\ttrain-rmse:31.97628\tvalidation-rmse:31.85381\n",
      "[199]\ttrain-rmse:31.75579\tvalidation-rmse:31.63343\n"
     ]
    }
   ],
   "source": [
    "# We need to prepare data as DMatrix objects\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "test = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "# We need to define parameters as dict\n",
    "params = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 3\n",
    "}\n",
    "# training, we set the early stopping rounds parameter\n",
    "model_xgb = xgb.train(params, \n",
    "          train, evals=[(train, \"train\"), (test, \"validation\")], \n",
    "          num_boost_round=200, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256.57397 , 108.301476, 119.78945 , ..., 126.498505, 297.5051  ,\n",
       "       165.24431 ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256.57397 , 108.301476, 119.78945 , ..., 126.498505, 297.5051  ,\n",
       "       165.24431 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.predict(test, ntree_limit=model_xgb.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test more XGBoost models, tune parameters\n",
    "\n",
    "# Run GridSearchCV with param grid of n_estimators and other params"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d091ba1997d2ad8548ed2a2e9fb4271b0c7b75568f81c7577ab54e0f83d6d2a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
